import { saveFileToGCS } from '../utils/gcs-image-storage';
import sharp from 'sharp';
import fs from 'fs';
import path from 'path';
import { getSystemSettings } from '../utils/settings';

const PERSISTENT_LOG_PATH = '/tmp/image-generation.log';

function persistentLog(message: string, data?: any) {
  const timestamp = new Date().toISOString();
  let logLine = `[${timestamp}] ${message}\n`;
  if (data !== undefined) {
    if (typeof data === 'object') {
      logLine += JSON.stringify(data, null, 2) + '\n';
    } else {
      logLine += data + '\n';
    }
  }
  try {
    fs.appendFileSync(PERSISTENT_LOG_PATH, logLine);
    console.log(message, data !== undefined ? data : '');
  } catch (e) {
    console.error('ì˜êµ¬ ë¡œê·¸ ì“°ê¸° ì‹¤íŒ¨:', e);
  }
}

export interface BackgroundRemovalResult {
  url: string;
  gsPath: string;
  fileName: string;
}

export interface BackgroundRemovalOptions {
  type?: 'foreground' | 'background';
  quality?: number;
  model?: 'small' | 'medium';
}

let modelInstance: any = null;
let processorInstance: any = null;
let isModelLoading = false;
let modelLoadPromise: Promise<void> | null = null;

const MODEL_ID = 'onnx-community/BiRefNet-portrait-ONNX';

async function getTransformers() {
  const { AutoModel, AutoProcessor, RawImage } = await import('@huggingface/transformers');
  return { AutoModel, AutoProcessor, RawImage };
}

export async function initializeBiRefNetModel(): Promise<void> {
  if (modelInstance && processorInstance) {
    console.log('âœ… [BiRefNet] Model already loaded');
    return;
  }

  if (isModelLoading && modelLoadPromise) {
    console.log('â³ [BiRefNet] Model is loading, waiting...');
    await modelLoadPromise;
    return;
  }

  isModelLoading = true;
  console.log(`ğŸš€ [BiRefNet] Loading model: ${MODEL_ID}`);
  
  modelLoadPromise = (async () => {
    try {
      const { AutoModel, AutoProcessor } = await getTransformers();
      
      console.log('ğŸ“¥ [BiRefNet] Downloading/loading model from HuggingFace...');
      
      modelInstance = await AutoModel.from_pretrained(MODEL_ID, {
        dtype: 'fp32',
      });
      
      processorInstance = await AutoProcessor.from_pretrained(MODEL_ID);
      
      console.log('âœ… [BiRefNet] Model loaded successfully');
    } catch (error) {
      console.error('âŒ [BiRefNet] Failed to load model:', error);
      modelInstance = null;
      processorInstance = null;
      throw error;
    } finally {
      isModelLoading = false;
    }
  })();

  await modelLoadPromise;
}

async function loadImage(imageUrl: string): Promise<Buffer> {
  if (imageUrl.startsWith('/uploads/')) {
    const localPath = path.join(process.cwd(), 'public', imageUrl);
    console.log(`ğŸ“‚ [BiRefNet] Loading local file: ${localPath}`);
    return fs.promises.readFile(localPath);
  }
  
  console.log(`ğŸŒ [BiRefNet] Fetching remote: ${imageUrl}`);
  const response = await fetch(imageUrl);
  if (!response.ok) {
    throw new Error(`Failed to fetch image: ${response.statusText}`);
  }
  return Buffer.from(await response.arrayBuffer());
}

async function convertToPng(imageBuffer: Buffer): Promise<Buffer> {
  const metadata = await sharp(imageBuffer).metadata();
  console.log(`ğŸ” [BiRefNet] Image format: ${metadata.format}, ${metadata.width}x${metadata.height}`);
  
  return await sharp(imageBuffer)
    .png()
    .toBuffer();
}

async function processWithBiRefNet(imageBuffer: Buffer): Promise<Buffer> {
  persistentLog('ğŸ”„ [processWithBiRefNet] ì‹œì‘', `ì…ë ¥ ë²„í¼: ${imageBuffer.length} bytes`);
  
  try {
    persistentLog('ğŸ“¥ [processWithBiRefNet] ëª¨ë¸ ì´ˆê¸°í™” ì‹œë„...');
    await initializeBiRefNetModel();
    persistentLog('âœ… [processWithBiRefNet] ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ');
    
    if (!modelInstance || !processorInstance) {
      persistentLog('âŒ [processWithBiRefNet] ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ');
      throw new Error('BiRefNet model not loaded');
    }

    const { RawImage } = await getTransformers();
    
    persistentLog('ğŸ–¼ï¸ [processWithBiRefNet] Sharpë¡œ raw í”½ì…€ ë°ì´í„° ì¶”ì¶œ ì¤‘...');
    let rawImageData: { data: Buffer; info: sharp.OutputInfo };
    let pngBuffer: Buffer;
    try {
      const sharpInstance = sharp(imageBuffer).ensureAlpha();
      rawImageData = await sharpInstance.raw().toBuffer({ resolveWithObject: true });
      pngBuffer = await sharp(imageBuffer).png().toBuffer();
      persistentLog('âœ… [processWithBiRefNet] Raw í”½ì…€ ì¶”ì¶œ ì™„ë£Œ', 
        `${rawImageData.info.width}x${rawImageData.info.height}, ${rawImageData.info.channels}ch, ${rawImageData.data.length} bytes`);
    } catch (sharpError) {
      persistentLog('âŒ [processWithBiRefNet] Sharp í”½ì…€ ì¶”ì¶œ ì‹¤íŒ¨', sharpError instanceof Error ? sharpError.message : String(sharpError));
      throw sharpError;
    }
    
    const originalWidth = rawImageData.info.width;
    const originalHeight = rawImageData.info.height;
    const channels = rawImageData.info.channels;
    
    persistentLog('ğŸ–¼ï¸ [processWithBiRefNet] RawImage ìƒì„± ì¤‘...');
    let image: any;
    try {
      const uint8Data = new Uint8ClampedArray(rawImageData.data);
      image = new RawImage(uint8Data, originalWidth, originalHeight, channels);
      persistentLog('âœ… [processWithBiRefNet] RawImage ìƒì„± ì™„ë£Œ');
    } catch (rawImageError) {
      persistentLog('âŒ [processWithBiRefNet] RawImage ìƒì„± ì‹¤íŒ¨', rawImageError instanceof Error ? rawImageError.message : String(rawImageError));
      throw rawImageError;
    }
    
    persistentLog(`ğŸ“ [processWithBiRefNet] ì´ë¯¸ì§€ í¬ê¸°`, `${originalWidth}x${originalHeight}`);
    
    persistentLog('ğŸ”„ [processWithBiRefNet] Preprocessor ì‹¤í–‰ ì¤‘...');
    let preprocessorOutput: any;
    try {
      preprocessorOutput = await processorInstance(image);
      const outputKeys = Object.keys(preprocessorOutput);
      persistentLog('âœ… [processWithBiRefNet] Preprocessor ì™„ë£Œ', `ì¶œë ¥ í‚¤: ${outputKeys.join(', ')}`);
    } catch (preprocessError) {
      persistentLog('âŒ [processWithBiRefNet] Preprocessor ì‹¤íŒ¨', preprocessError instanceof Error ? preprocessError.message : String(preprocessError));
      throw preprocessError;
    }
    
    persistentLog('ğŸ§  [processWithBiRefNet] Inference ì‹¤í–‰ ì¤‘...');
    let outputs: any;
    try {
      const startTime = Date.now();
      const inputTensor = preprocessorOutput.pixel_values || preprocessorOutput;
      const modelInputs = { input_image: inputTensor };
      persistentLog('ğŸ“¤ [processWithBiRefNet] ëª¨ë¸ ì…ë ¥ í‚¤', Object.keys(modelInputs).join(', '));
      outputs = await modelInstance(modelInputs);
      const inferenceTime = Date.now() - startTime;
      persistentLog(`âœ… [processWithBiRefNet] Inference ì™„ë£Œ`, `${inferenceTime}ms`);
    } catch (inferenceError) {
      persistentLog('âŒ [processWithBiRefNet] Inference ì‹¤íŒ¨', inferenceError instanceof Error ? inferenceError.message : String(inferenceError));
      throw inferenceError;
    }
    
    const output = outputs.output || outputs.logits || Object.values(outputs)[0];
    if (!output) {
      persistentLog('âŒ [processWithBiRefNet] ì¶œë ¥ í…ì„œê°€ ì—†ìŒ', `keys: ${Object.keys(outputs).join(', ')}`);
      throw new Error('No output tensor found');
    }
    
    persistentLog('ğŸ¨ [processWithBiRefNet] ë§ˆìŠ¤í¬ ì²˜ë¦¬ ì¤‘...');
    const maskData = output.data;
    const maskWidth = output.dims[3];
    const maskHeight = output.dims[2];
    persistentLog(`ğŸ“Š [processWithBiRefNet] ë§ˆìŠ¤í¬ í¬ê¸°`, `${maskWidth}x${maskHeight}, data length: ${maskData.length}`);
    
    const sigmoidMask = new Float32Array(maskData.length);
    for (let i = 0; i < maskData.length; i++) {
      sigmoidMask[i] = 1.0 / (1.0 + Math.exp(-maskData[i]));
    }
    
    const uint8Mask = new Uint8Array(sigmoidMask.length);
    for (let i = 0; i < sigmoidMask.length; i++) {
      uint8Mask[i] = Math.round(sigmoidMask[i] * 255);
    }
    persistentLog('âœ… [processWithBiRefNet] Sigmoid ë§ˆìŠ¤í¬ ë³€í™˜ ì™„ë£Œ');
    
    const maskImage = sharp(Buffer.from(uint8Mask), {
      raw: { width: maskWidth, height: maskHeight, channels: 1 }
    });
    
    const resizedMask = await maskImage
      .resize(originalWidth, originalHeight)
      .raw()
      .toBuffer();
    persistentLog('âœ… [processWithBiRefNet] ë§ˆìŠ¤í¬ ë¦¬ì‚¬ì´ì¦ˆ ì™„ë£Œ', `${resizedMask.length} bytes`);
    
    const originalImage = await sharp(pngBuffer)
      .ensureAlpha()
      .raw()
      .toBuffer({ resolveWithObject: true });
    
    const { data: rgbaData, info } = originalImage;
    const resultBuffer = Buffer.alloc(info.width * info.height * 4);
    
    for (let i = 0; i < info.width * info.height; i++) {
      resultBuffer[i * 4] = rgbaData[i * 4];
      resultBuffer[i * 4 + 1] = rgbaData[i * 4 + 1];
      resultBuffer[i * 4 + 2] = rgbaData[i * 4 + 2];
      resultBuffer[i * 4 + 3] = resizedMask[i];
    }
    persistentLog('âœ… [processWithBiRefNet] ì•ŒíŒŒ ì±„ë„ í•©ì„± ì™„ë£Œ');
    
    const finalImage = await sharp(resultBuffer, {
      raw: { width: info.width, height: info.height, channels: 4 }
    })
      .png()
      .toBuffer();
    
    persistentLog(`âœ… [processWithBiRefNet] ìµœì¢… ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ`, `${finalImage.length} bytes`);
    return finalImage;
    
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error);
    const errorStack = error instanceof Error ? error.stack : undefined;
    persistentLog('âŒ [processWithBiRefNet] ì „ì²´ ì‹¤íŒ¨', { message: errorMsg, stack: errorStack?.slice(0, 500) });
    throw error;
  }
}

async function invertAlphaComposite(originalBuffer: Buffer, foregroundBuffer: Buffer): Promise<Buffer> {
  const foreground = sharp(foregroundBuffer);
  
  const { data: fgData, info: fgInfo } = await foreground
    .ensureAlpha()
    .raw()
    .toBuffer({ resolveWithObject: true });
  
  const invertedAlpha = Buffer.alloc(fgInfo.width * fgInfo.height);
  for (let i = 0; i < invertedAlpha.length; i++) {
    const alphaValue = fgData[i * 4 + 3];
    invertedAlpha[i] = 255 - alphaValue;
  }
  
  const alphaMask = await sharp(invertedAlpha, {
    raw: { width: fgInfo.width, height: fgInfo.height, channels: 1 }
  })
    .png()
    .toBuffer();
  
  return await sharp(originalBuffer)
    .resize(fgInfo.width, fgInfo.height)
    .ensureAlpha()
    .joinChannel(alphaMask)
    .png()
    .toBuffer();
}

export async function removeImageBackground(
  imageUrl: string,
  userId: number | string,
  options?: BackgroundRemovalOptions
): Promise<BackgroundRemovalResult> {
  console.log(`ğŸ”§ [BiRefNet] Starting for user ${userId}: ${imageUrl}`);
  
  try {
    const outputType = options?.type || 'foreground';
    console.log(`âš™ï¸ [BiRefNet] Settings: type=${outputType}`);
    
    const imageBuffer = await loadImage(imageUrl);
    console.log(`ğŸ“¥ [BiRefNet] Loaded image: ${imageBuffer.length} bytes`);
    
    let resultBuffer = await processWithBiRefNet(imageBuffer);
    
    if (outputType === 'background') {
      console.log(`ğŸ”„ [BiRefNet] Inverting to get background only`);
      resultBuffer = await invertAlphaComposite(imageBuffer, resultBuffer);
      console.log(`âœ… [BiRefNet] Background extracted: ${resultBuffer.length} bytes`);
    }
    
    console.log(`âœ… [BiRefNet] Processed (${outputType}): ${resultBuffer.length} bytes`);
    
    const timestamp = Date.now();
    const suffix = outputType === 'background' ? '_bgonly' : '_nobg';
    const fileName = `${timestamp}${suffix}.png`;
    
    const gcsResult = await saveFileToGCS(
      resultBuffer,
      userId,
      'background-removed',
      fileName,
      'image/png'
    );
    
    console.log(`ğŸ“¤ [BiRefNet] Uploaded to GCS: ${gcsResult.originalUrl}`);
    
    return {
      url: gcsResult.originalUrl,
      gsPath: gcsResult.gsPath,
      fileName: gcsResult.fileName,
    };
    
  } catch (error) {
    console.error('âŒ [BiRefNet] Error:', error);
    throw new Error(`BiRefNet background removal failed: ${error instanceof Error ? error.message : String(error)}`);
  }
}

export async function removeBackgroundFromBuffer(
  imageBuffer: Buffer,
  userId: number | string,
  options?: BackgroundRemovalOptions
): Promise<BackgroundRemovalResult> {
  persistentLog(`ğŸ”§ [BiRefNet Buffer] Starting for user ${userId}`, `ë²„í¼ í¬ê¸°: ${imageBuffer.length} bytes`);
  
  try {
    const outputType = options?.type || 'foreground';
    persistentLog(`âš™ï¸ [BiRefNet Buffer] Settings`, `type=${outputType}`);
    
    persistentLog('ğŸ§  [BiRefNet Buffer] processWithBiRefNet í˜¸ì¶œ ì‹œì‘...');
    let resultBuffer = await processWithBiRefNet(imageBuffer);
    persistentLog('âœ… [BiRefNet Buffer] processWithBiRefNet ì™„ë£Œ', `ê²°ê³¼: ${resultBuffer.length} bytes`);
    
    if (outputType === 'background') {
      persistentLog(`ğŸ”„ [BiRefNet Buffer] Inverting to get background only`);
      resultBuffer = await invertAlphaComposite(imageBuffer, resultBuffer);
      persistentLog(`âœ… [BiRefNet Buffer] Background extracted`, `${resultBuffer.length} bytes`);
    }
    
    persistentLog(`âœ… [BiRefNet Buffer] Processed (${outputType})`, `${resultBuffer.length} bytes`);
    
    const timestamp = Date.now();
    const suffix = outputType === 'background' ? '_bgonly' : '_nobg';
    const fileName = `${timestamp}${suffix}.png`;
    
    const gcsResult = await saveFileToGCS(
      resultBuffer,
      userId,
      'background-removed',
      fileName,
      'image/png'
    );
    
    persistentLog(`ğŸ“¤ [BiRefNet Buffer] Uploaded to GCS`, gcsResult.originalUrl);
    
    return {
      url: gcsResult.originalUrl,
      gsPath: gcsResult.gsPath,
      fileName: gcsResult.fileName,
    };
    
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error);
    const errorStack = error instanceof Error ? error.stack : undefined;
    persistentLog('âŒ [BiRefNet Buffer] ì—ëŸ¬ ë°œìƒ', { message: errorMsg, stack: errorStack });
    throw new Error(`BiRefNet background removal failed: ${errorMsg}`);
  }
}
